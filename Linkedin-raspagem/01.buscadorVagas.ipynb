{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a4297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\luciana.santos\\appdata\\local\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\luciana.santos\\appdata\\local\\anaconda3\\lib\\site-packages (from openpyxl) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "##!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a87259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e82c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import List, Dict, Optional, Set\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Cabeçalho básico para evitar bloqueio por user-agent vazio\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/123.0 Safari/537.36\"\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc9858e",
   "metadata": {},
   "source": [
    "#### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eba702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_text_or_none(elem) -> Optional[str]:\n",
    "    \"\"\"Retorna o texto stripado ou None se elem for None.\"\"\"\n",
    "    return elem.get_text(strip=True) if elem else None\n",
    "\n",
    "\n",
    "def safe_criteria(criteria_list, index: int) -> Optional[str]:\n",
    "    \"\"\"Retorna um critério da lista (ex: experiência, tipo de contrato) se existir.\"\"\"\n",
    "    try:\n",
    "        return criteria_list[index].get_text(strip=True)\n",
    "    except (IndexError, AttributeError):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf2d81b",
   "metadata": {},
   "source": [
    "#### Buscador IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "670f1132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_job_ids(\n",
    "    title: str,\n",
    "    location: str,\n",
    "    num_pages: int,\n",
    "    pause: float = 0.5,\n",
    "    verbose: bool = True,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Busca job_ids de vagas no LinkedIn Jobs (endpoint 'seeMoreJobPostings').\n",
    "\n",
    "    :param title: termo de busca (ex: 'engineer', 'scientist').\n",
    "    :param location: localização (ex: 'Brazil', 'Lisbon, Portugal').\n",
    "    :param num_pages: número de páginas a percorrer.\n",
    "    :param pause: tempo de espera entre requisições (segundos).\n",
    "    :param verbose: se True, imprime logs simples.\n",
    "    :return: lista de job_ids (sem duplicados).\n",
    "    \"\"\"\n",
    "    job_ids: Set[str] = set()\n",
    "\n",
    "    keywords = f\"data {title}\".strip()\n",
    "    keywords_encoded = quote_plus(keywords)\n",
    "    location_encoded = quote_plus(location)\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        session.headers.update(HEADERS)\n",
    "\n",
    "        for page in range(num_pages):\n",
    "            start = page * 10  # cada página costuma ter 10 vagas\n",
    "            list_url = (\n",
    "                \"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search\"\n",
    "                f\"?keywords={keywords_encoded}\"\n",
    "                f\"&location={location_encoded}\"\n",
    "                \"&position=1&pageNum=0\"\n",
    "                f\"&start={start}\"\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                response = session.get(list_url, timeout=10)\n",
    "            except requests.RequestException as e:\n",
    "                if verbose:\n",
    "                    print(f\"[ERRO] Falha na requisição da página {page}: {e}\")\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"[LISTA] Página {page} - status {response.status_code}\")\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                if verbose:\n",
    "                    print(f\"[AVISO] Pulando página {page} (status {response.status_code})\")\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            page_jobs = soup.find_all(\"li\")\n",
    "\n",
    "            if not page_jobs and verbose:\n",
    "                print(f\"[AVISO] Nenhuma vaga encontrada na página {page}\")\n",
    "\n",
    "            for job in page_jobs:\n",
    "                base_card_div = job.find(\"div\", {\"class\": \"base-card\"})\n",
    "                if not base_card_div:\n",
    "                    continue\n",
    "\n",
    "                urn = base_card_div.get(\"data-entity-urn\")\n",
    "                if not urn:\n",
    "                    continue\n",
    "\n",
    "                parts = urn.split(\":\")\n",
    "                if len(parts) < 4:\n",
    "                    continue\n",
    "\n",
    "                job_id = parts[3]\n",
    "                job_ids.add(job_id)\n",
    "                if verbose:\n",
    "                    print(f\"[JOB ID] {job_id}\")\n",
    "\n",
    "            time.sleep(pause)\n",
    "\n",
    "    return list(job_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28098bcb",
   "metadata": {},
   "source": [
    "#### Scrape de detalhes da vaga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475e8bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_job_page(html: str, job_id: str) -> Dict[str, Optional[str]]:\n",
    "    \"\"\"Extrai os dados de uma página de vaga do LinkedIn.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    job_post: Dict[str, Optional[str]] = {}\n",
    "\n",
    "    # Título da vaga\n",
    "    job_post[\"job_title\"] = get_text_or_none(\n",
    "        soup.find(\n",
    "            \"h2\",\n",
    "            {\n",
    "                \"class\": (\n",
    "                    \"top-card-layout__title font-sans text-lg \"\n",
    "                    \"papabear:text-xl font-bold leading-open \"\n",
    "                    \"text-color-text mb-0 topcard__title\"\n",
    "                )\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Nome da empresa\n",
    "    job_post[\"company_name\"] = get_text_or_none(\n",
    "        soup.find(\n",
    "            \"a\",\n",
    "            {\"class\": \"topcard__org-name-link topcard__flavor--black-link\"},\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Critérios (nível de experiência, tipo de contrato, etc.)\n",
    "    criteria = soup.find_all(\n",
    "        \"span\",\n",
    "        {\n",
    "            \"class\": (\n",
    "                \"description__job-criteria-text \"\n",
    "                \"description__job-criteria-text--criteria\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    job_post[\"experience_level\"] = safe_criteria(criteria, 0)\n",
    "    job_post[\"type_of_contract\"] = safe_criteria(criteria, 1)\n",
    "    # Se quiser, dá pra reativar:\n",
    "    # job_post[\"job_role\"] = safe_criteria(criteria, 2)\n",
    "    # job_post[\"field\"] = safe_criteria(criteria, 3)\n",
    "\n",
    "    # Easy apply (True/False)\n",
    "    try:\n",
    "        offsite_icon = soup.find(\n",
    "            \"icon\",\n",
    "            {\"data-svg-class-name\": \"apply-button__offsite-apply-icon-svg\"},\n",
    "        )\n",
    "        job_post[\"easy_apply\"] = False if offsite_icon else True\n",
    "    except Exception:\n",
    "        job_post[\"easy_apply\"] = None\n",
    "\n",
    "    # Tempo desde a postagem\n",
    "    job_post[\"time_posted\"] = get_text_or_none(\n",
    "        soup.find(\n",
    "            \"span\",\n",
    "            {\n",
    "                \"class\": (\n",
    "                    \"posted-time-ago__text \"\n",
    "                    \"topcard__flavor--metadata\"\n",
    "                )\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Número de candidatos\n",
    "    job_post[\"num_applicants\"] = get_text_or_none(\n",
    "        soup.find(\"span\", {\"class\": \"num-applicants__caption\"})\n",
    "    )\n",
    "\n",
    "    # Link da vaga\n",
    "    job_post[\"job_link\"] = f\"https://www.linkedin.com/jobs/view/{job_id}/\"\n",
    "\n",
    "    return job_post\n",
    "\n",
    "\n",
    "def scrape_jobs(\n",
    "    id_list: List[str],\n",
    "    sleep_seconds: float = 0.5,\n",
    "    verbose: bool = True,\n",
    ") -> List[Dict[str, Optional[str]]]:\n",
    "    \"\"\"\n",
    "    Faz scrape dos detalhes de uma lista de job_ids do LinkedIn.\n",
    "\n",
    "    :param id_list: lista de IDs de vagas.\n",
    "    :param sleep_seconds: pausa entre requisições, para evitar 429.\n",
    "    :param verbose: se True, imprime status das requisições.\n",
    "    :return: lista de dicionários com dados da vaga.\n",
    "    \"\"\"\n",
    "    job_list: List[Dict[str, Optional[str]]] = []\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        session.headers.update(HEADERS)\n",
    "\n",
    "        for job_id in id_list:\n",
    "            job_url = f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{job_id}\"\n",
    "\n",
    "            try:\n",
    "                response = session.get(job_url, timeout=10)\n",
    "            except requests.RequestException as e:\n",
    "                if verbose:\n",
    "                    print(f\"[ERRO] Falha ao buscar job {job_id}: {e}\")\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"[DETALHE] {job_id} - status {response.status_code}\")\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                if verbose:\n",
    "                    print(f\"[AVISO] Pulando job {job_id} (status {response.status_code})\")\n",
    "                continue\n",
    "\n",
    "            job_post = parse_job_page(response.text, job_id)\n",
    "            job_list.append(job_post)\n",
    "\n",
    "            time.sleep(sleep_seconds)\n",
    "\n",
    "    return job_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98d4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linkedin_pipeline(\n",
    "    title: str,\n",
    "    location: str,\n",
    "    num_pages: int,\n",
    "    out_csv: Optional[str] = None,\n",
    "    verbose: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Roda o pipeline completo:\n",
    "    - Busca job_ids\n",
    "    - Scrapa detalhes\n",
    "    - Retorna DataFrame e opcionalmente salva CSV\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"=== Buscando job IDs ===\")\n",
    "    ids = fetch_job_ids(title, location, num_pages, verbose=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nTotal de IDs encontrados: {len(ids)}\")\n",
    "        print(\"=== Scraping detalhes das vagas ===\")\n",
    "\n",
    "    job_list = scrape_jobs(ids, verbose=verbose)\n",
    "\n",
    "    df = pd.DataFrame(job_list)\n",
    "\n",
    "    if out_csv is not None:\n",
    "        df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "        if verbose:\n",
    "            print(f\"\\n[OK] Dados salvos em: {out_csv}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49372ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def salvar_em_excel(\n",
    "    df: pd.DataFrame,\n",
    "    caminho_arquivo: str = \"linkedin_jobs.xlsx\",\n",
    "    sheet_name: str = \"Vagas\",\n",
    "    col_widths: dict | None = None,  # ex: {\"job_title\": 60, \"company_name\": 30}\n",
    "    auto_row_height: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Salva DataFrame em Excel com ajuste de largura das colunas.\n",
    "    \n",
    "    :param df: DataFrame com os dados.\n",
    "    :param caminho_arquivo: nome/ caminho do arquivo .xlsx.\n",
    "    :param sheet_name: nome da aba.\n",
    "    :param col_widths: dict opcional {nome_coluna: largura_em_excel}.\n",
    "    :param auto_row_height: se True, ativa quebra de linha (wrap_text),\n",
    "                            o que ajuda em textos muito grandes.\n",
    "    \"\"\"\n",
    "    from openpyxl.utils import get_column_letter\n",
    "    from openpyxl.styles import Alignment\n",
    "\n",
    "    if col_widths is None:\n",
    "        col_widths = {}\n",
    "\n",
    "    with pd.ExcelWriter(caminho_arquivo, engine=\"openpyxl\") as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "        ws = writer.sheets[sheet_name]\n",
    "\n",
    "        # 1) Ajuste automático de largura baseado no conteúdo\n",
    "        for col_idx, column in enumerate(ws.columns, start=1):\n",
    "            max_length = 0\n",
    "            col_letter = get_column_letter(col_idx)\n",
    "\n",
    "            for cell in column:\n",
    "                value = cell.value\n",
    "                if value is not None:\n",
    "                    value_len = len(str(value))\n",
    "                    if value_len > max_length:\n",
    "                        max_length = value_len\n",
    "\n",
    "            # margem extra\n",
    "            adjusted_width = max_length + 2\n",
    "            ws.column_dimensions[col_letter].width = adjusted_width\n",
    "\n",
    "        # 2) Sobrescrever larguras específicas via col_widths\n",
    "        #    (usa nome da coluna do DataFrame)\n",
    "        header_row = next(ws.iter_rows(min_row=1, max_row=1))\n",
    "        col_name_to_letter = {\n",
    "            cell.value: cell.column_letter for cell in header_row if cell.value\n",
    "        }\n",
    "\n",
    "        for col_name, width in col_widths.items():\n",
    "            if col_name in col_name_to_letter:\n",
    "                ws.column_dimensions[col_name_to_letter[col_name]].width = width\n",
    "\n",
    "        # 3) (Opcional) Quebra de linha + altura de linha (para textos longos)\n",
    "        if auto_row_height:\n",
    "            for row in ws.iter_rows(min_row=1):\n",
    "                for cell in row:\n",
    "                    cell.alignment = Alignment(wrap_text=True)\n",
    "            # Excel recalcula a altura automaticamente quando wrap_text está ativo\n",
    "\n",
    "    print(f\"Arquivo Excel salvo em: {caminho_arquivo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401b3eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Buscando job IDs ===\n",
      "[LISTA] Página 0 - status 200\n",
      "[JOB ID] 4318327757\n",
      "[JOB ID] 4308497997\n",
      "[JOB ID] 4281828542\n",
      "[JOB ID] 4233957493\n",
      "[JOB ID] 4337472760\n",
      "[JOB ID] 4312919215\n",
      "[JOB ID] 4298239221\n",
      "[JOB ID] 4324753186\n",
      "[JOB ID] 4310476364\n",
      "[JOB ID] 4317491191\n",
      "[LISTA] Página 1 - status 200\n",
      "[JOB ID] 4303420983\n",
      "[JOB ID] 4231033954\n",
      "[JOB ID] 4312301348\n",
      "[JOB ID] 4316823422\n",
      "[JOB ID] 4331368566\n",
      "[JOB ID] 4314223388\n",
      "[JOB ID] 3969555543\n",
      "[JOB ID] 4334041808\n",
      "[JOB ID] 4315447335\n",
      "[JOB ID] 4331348122\n",
      "[LISTA] Página 2 - status 200\n",
      "[JOB ID] 4334386540\n",
      "[JOB ID] 4307252914\n",
      "[JOB ID] 4245979421\n",
      "[JOB ID] 4333019146\n",
      "[JOB ID] 4320660148\n",
      "[JOB ID] 4307685458\n",
      "[JOB ID] 4214699583\n",
      "[JOB ID] 4295464589\n",
      "[JOB ID] 4313394952\n",
      "[JOB ID] 4312861310\n",
      "\n",
      "Total de IDs encontrados: 30\n",
      "=== Scraping detalhes das vagas ===\n",
      "[DETALHE] 4310476364 - status 200\n",
      "[DETALHE] 4214699583 - status 200\n",
      "[DETALHE] 4318327757 - status 200\n",
      "[DETALHE] 4316823422 - status 200\n",
      "[DETALHE] 4337472760 - status 200\n",
      "[DETALHE] 4303420983 - status 200\n",
      "[DETALHE] 3969555543 - status 200\n",
      "[DETALHE] 4231033954 - status 200\n",
      "[DETALHE] 4245979421 - status 200\n",
      "[DETALHE] 4334386540 - status 200\n",
      "[DETALHE] 4233957493 - status 429\n",
      "[AVISO] Pulando job 4233957493 (status 429)\n",
      "[DETALHE] 4317491191 - status 429\n",
      "[AVISO] Pulando job 4317491191 (status 429)\n",
      "[DETALHE] 4331348122 - status 429\n",
      "[AVISO] Pulando job 4331348122 (status 429)\n",
      "[DETALHE] 4320660148 - status 429\n",
      "[AVISO] Pulando job 4320660148 (status 429)\n",
      "[DETALHE] 4307252914 - status 429\n",
      "[AVISO] Pulando job 4307252914 (status 429)\n",
      "[DETALHE] 4312919215 - status 429\n",
      "[AVISO] Pulando job 4312919215 (status 429)\n",
      "[DETALHE] 4295464589 - status 429\n",
      "[AVISO] Pulando job 4295464589 (status 429)\n",
      "[DETALHE] 4314223388 - status 429\n",
      "[AVISO] Pulando job 4314223388 (status 429)\n",
      "[DETALHE] 4315447335 - status 429\n",
      "[AVISO] Pulando job 4315447335 (status 429)\n",
      "[DETALHE] 4313394952 - status 429\n",
      "[AVISO] Pulando job 4313394952 (status 429)\n",
      "[DETALHE] 4307685458 - status 429\n",
      "[AVISO] Pulando job 4307685458 (status 429)\n",
      "[DETALHE] 4312301348 - status 429\n",
      "[AVISO] Pulando job 4312301348 (status 429)\n",
      "[DETALHE] 4281828542 - status 429\n",
      "[AVISO] Pulando job 4281828542 (status 429)\n",
      "[DETALHE] 4333019146 - status 429\n",
      "[AVISO] Pulando job 4333019146 (status 429)\n",
      "[DETALHE] 4298239221 - status 429\n",
      "[AVISO] Pulando job 4298239221 (status 429)\n",
      "[DETALHE] 4308497997 - status 429\n",
      "[AVISO] Pulando job 4308497997 (status 429)\n",
      "[DETALHE] 4331368566 - status 429\n",
      "[AVISO] Pulando job 4331368566 (status 429)\n",
      "[DETALHE] 4324753186 - status 429\n",
      "[AVISO] Pulando job 4324753186 (status 429)\n",
      "[DETALHE] 4312861310 - status 429\n",
      "[AVISO] Pulando job 4312861310 (status 429)\n",
      "[DETALHE] 4334041808 - status 429\n",
      "[AVISO] Pulando job 4334041808 (status 429)\n",
      "Arquivo Excel salvo em: linkedin_jobs_brazil_engineer.xlsx\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "\n",
    "df = run_linkedin_pipeline(\n",
    "    title=\"engineer\",\n",
    "    location=\"Brazil\",\n",
    "    num_pages=3,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "col_widths_personalizadas = {\n",
    "    \"job_title\": 60,        # título bem largo\n",
    "    \"company_name\": 30,     # empresa médio\n",
    "    \"experience_level\": 20,\n",
    "    \"type_of_contract\": 20,\n",
    "    \"num_applicants\": 18,\n",
    "    \"easy_apply\": 12,\n",
    "    \"time_posted\": 18,\n",
    "    \"job_link\": 50,         # URL grande\n",
    "}\n",
    "\n",
    "salvar_em_excel(\n",
    "    df,\n",
    "    caminho_arquivo=\"linkedin_jobs_brazil_engineer.xlsx\",\n",
    "    sheet_name=\"Vagas\",\n",
    "    col_widths=col_widths_personalizadas,\n",
    "    auto_row_height=True,   # quebra linha em textos longos\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
