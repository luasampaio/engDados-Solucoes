{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63444c8",
   "metadata": {},
   "source": [
    "####  O que é Pandera?\n",
    "- Pandera é uma biblioteca Python open-source projetada para validação de dados em DataFrames do pandas. Ela permite definir esquemas (schemas) para verificar tipos de dados, valores nulos, restrições personalizadas e testes estatísticos, ajudando a garantir a integridade dos dados em pipelines de ETL, machine learning e análise de dados. \n",
    "- É inspirada em bibliotecas como Great Expectations e Pydantic, e integra-se perfeitamente com o pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efb8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandera.pandas as pa  # <- novo\n",
    "# opcional: você pode usar os checks via pa.Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75910bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DISABLE_PANDERA_IMPORT_WARNING\"] = \"True\"\n",
    "import pandera.pandas as pa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79e0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U pip setuptools wheel\n",
    "#%pip install numpy pandas pandera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da83bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandera.pandas as pa\n",
    "from pandera import Check  # ainda funciona; alternativamente use pa.Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e5e9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.3 0.26.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, pandera as pa\n",
    "print(pd.__version__, pa.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ca5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandera.pandas as pa  # novo import\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"idUsuario\": pa.Column(\n",
    "            pa.Int64,\n",
    "            checks=[pa.Check.ge(1)],\n",
    "            nullable=False,\n",
    "            coerce=True,\n",
    "            unique=True,\n",
    "        ),\n",
    "        \"nomeEvento\": pa.Column(\n",
    "            str,\n",
    "            checks=[pa.Check.str_length(min_value=1, max_value=200)],\n",
    "            nullable=False,\n",
    "            coerce=True,\n",
    "        ),\n",
    "        \"dataHora\": pa.Column(\n",
    "            pa.DateTime,\n",
    "            nullable=False,\n",
    "            coerce=True,\n",
    "        ),\n",
    "        \"metadado\": pa.Column(\n",
    "            object,\n",
    "            nullable=True,\n",
    "            checks=pa.Check(\n",
    "                lambda x: pd.isna(x) or isinstance(x, dict),\n",
    "                element_wise=True,\n",
    "                error=\"metadado deve ser dict (ou NA).\",\n",
    "            ),\n",
    "        ),\n",
    "    },\n",
    "    strict=True,\n",
    "    ordered=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e93e2",
   "metadata": {},
   "source": [
    "### Observações:\n",
    "- coerce=True padroniza tipos na entrada (excelente para dados CSV/JSON).\n",
    "\n",
    "- Para regex em dataHora, sua ideia funciona, mas usar pa.DateTime é mais seguro e cobre timezone, milissegundos etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c12303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erros de validação:\n",
      "     column failure_case index schema_context                           check  \\\n",
      "0  dataHora         None  None         Column  coerce_dtype('datetime64[ns]')   \n",
      "1  dataHora       object  None         Column         dtype('datetime64[ns]')   \n",
      "\n",
      "  check_number  \n",
      "0         None  \n",
      "1         None  \n"
     ]
    }
   ],
   "source": [
    "import pandera as pa\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"idUsuario\": [1, 2, 3],\n",
    "    \"nomeEvento\": [\"login\", \"logout\", \"pageview\"],\n",
    "    \"dataHora\": [\"2025-10-31T09:47:00\", \"2025-10-31T10:00:00Z\", \"2025-10-31 10:15:00-03:00\"],\n",
    "    \"metadado\": [ {\"ip\":\"1.2.3.4\"}, None, {\"browser\":\"Firefox\"} ],\n",
    "})\n",
    "\n",
    "try:\n",
    "    df_valid = schema.validate(df, lazy=True)  # lazy coleta todos os erros\n",
    "    print(\"OK! Dados válidos.\")\n",
    "except pa.errors.SchemaErrors as err:\n",
    "    print(\"Erros de validação:\")\n",
    "    print(err.failure_cases)  # dataframe com detalhes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ebdeff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luciana.santos\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandera\\_pandas_deprecated.py:149: FutureWarning: Importing pandas-specific classes and functions from the\n",
      "top-level pandera module will be **removed in a future version of pandera**.\n",
      "If you're using pandera to validate pandas objects, we highly recommend updating\n",
      "your import:\n",
      "\n",
      "```\n",
      "# old import\n",
      "import pandera as pa\n",
      "\n",
      "# new import\n",
      "import pandera.pandas as pa\n",
      "```\n",
      "\n",
      "If you're using pandera to validate objects from other compatible libraries\n",
      "like pyspark or polars, see the supported libraries section of the documentation\n",
      "for more information on how to import pandera:\n",
      "\n",
      "https://pandera.readthedocs.io/en/stable/supported_libraries.html\n",
      "\n",
      "To disable this warning, set the environment variable:\n",
      "\n",
      "```\n",
      "export DISABLE_PANDERA_IMPORT_WARNING=True\n",
      "```\n",
      "\n",
      "  warnings.warn(_future_warning, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandera as pa\n",
    "\n",
    "schema_1 = pa.DataFrameSchema({\n",
    "    \"nomeEvento\": pa.Column(\n",
    "        str,\n",
    "        checks=[\n",
    "            pa.Check.isin({\"login\",\"logout\",\"pageview\"}),          # enum\n",
    "            pa.Check.str_length(min_value=1, max_value=200),       # tamanho\n",
    "            pa.Check.str_matches(r\"^[a-z]+(?:_[a-z]+)*$\"),         # snake_case\n",
    "        ],\n",
    "        coerce=True,\n",
    "    )\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5edaf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Schema DataFrameSchema(columns={'nomeEvento': <Schema Column(name=nomeEvento, type=DataType(str))>}, checks=[], parsers=[], index=None, dtype=None, coerce=False, strict=False, name=None, ordered=False, unique=None, report_duplicates=all, unique_column_names=False, add_missing_columns=False, title=None, description=None, metadata=None, drop_invalid_rows=False)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(schema_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947115ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Schema DataFrameSchema(\n",
      "    columns={\n",
      "        'nomeEvento': <Schema Column(name=nomeEvento, type=DataType(str))>\n",
      "    },\n",
      "    checks=[],\n",
      "    parsers=[],\n",
      "    coerce=False,\n",
      "    dtype=None,\n",
      "    index=None,\n",
      "    strict=False,\n",
      "    name=None,\n",
      "    ordered=False,\n",
      "    unique_column_names=False,\n",
      "    metadata=None, \n",
      "    add_missing_columns=False\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(schema_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e94035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema({\n",
    "    \"idUsuario\": pa.Column(pa.Int64, checks=[pa.Check.ge(1)], unique=True, coerce=True),\n",
    "    \"tempoSessaoSeg\": pa.Column(pa.Int64, checks=[pa.Check.ge(0)], coerce=True),\n",
    "    \"taxaConversao\": pa.Column(float, checks=[pa.Check.between(0, 1)], coerce=True),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b280f59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Schema DataFrameSchema(\n",
      "    columns={\n",
      "        'idUsuario': <Schema Column(name=idUsuario, type=DataType(int64))>\n",
      "        'tempoSessaoSeg': <Schema Column(name=tempoSessaoSeg, type=DataType(int64))>\n",
      "        'taxaConversao': <Schema Column(name=taxaConversao, type=DataType(float64))>\n",
      "    },\n",
      "    checks=[],\n",
      "    parsers=[],\n",
      "    coerce=False,\n",
      "    dtype=None,\n",
      "    index=None,\n",
      "    strict=False,\n",
      "    name=None,\n",
      "    ordered=False,\n",
      "    unique_column_names=False,\n",
      "    metadata=None, \n",
      "    add_missing_columns=False\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805c821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falhas:\n",
      "   column    failure_case index   schema_context                check  \\\n",
      "0   None  tempoSessaoSeg  None  DataFrameSchema  column_in_dataframe   \n",
      "1   None   taxaConversao  None  DataFrameSchema  column_in_dataframe   \n",
      "\n",
      "  check_number  \n",
      "0         None  \n",
      "1         None  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_ok = schema.validate(df, lazy=True)\n",
    "except pa.errors.SchemaErrors as e:\n",
    "    print(\"Falhas:\\n\", e.failure_cases)  # DataFrame com detalhes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f47790",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_eventos = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"idUsuario\": pa.Column(pa.Int64, checks=[pa.Check.ge(1)], coerce=True),\n",
    "        \"nomeEvento\": pa.Column(\n",
    "            str,\n",
    "            checks=[pa.Check.isin({\"login\",\"logout\",\"pageview\"}),\n",
    "                    pa.Check.str_length(1, 200)],\n",
    "            coerce=True,\n",
    "        ),\n",
    "        \"dataHora\": pa.Column(pa.DateTime, coerce=True),\n",
    "        \"metadado\": pa.Column(object, nullable=True),\n",
    "    },\n",
    "    checks=[\n",
    "        pa.Check(\n",
    "            lambda df: not df.duplicated(subset=[\"idUsuario\",\"dataHora\"]).any(),\n",
    "            error=\"(idUsuario, dataHora) deve ser único.\"\n",
    "        ),\n",
    "        pa.Check(\n",
    "            lambda df: (\n",
    "                (~(df[\"nomeEvento\"] == \"login\")) |\n",
    "                (df[\"metadado\"].apply(lambda x: isinstance(x, dict) and \"ip\" in x))\n",
    "            ).all(),\n",
    "            error=\"Eventos 'login' devem ter metadado com 'ip'.\"\n",
    "        ),\n",
    "    ],\n",
    "    strict=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6815cf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Schema DataFrameSchema(\n",
      "    columns={\n",
      "        'idUsuario': <Schema Column(name=idUsuario, type=DataType(int64))>\n",
      "        'nomeEvento': <Schema Column(name=nomeEvento, type=DataType(str))>\n",
      "        'dataHora': <Schema Column(name=dataHora, type=DataType(datetime64[ns]))>\n",
      "        'metadado': <Schema Column(name=metadado, type=DataType(object))>\n",
      "    },\n",
      "    checks=[\n",
      "        <Check <lambda>: (idUsuario, dataHora) deve ser único.>\n",
      "        <Check <lambda>: Eventos 'login' devem ter metadado com 'ip'.>\n",
      "    ],\n",
      "    parsers=[],\n",
      "    coerce=False,\n",
      "    dtype=None,\n",
      "    index=None,\n",
      "    strict=True,\n",
      "    name=None,\n",
      "    ordered=False,\n",
      "    unique_column_names=False,\n",
      "    metadata=None, \n",
      "    add_missing_columns=False\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(schema_eventos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
